# Urban Park Design with Reinforcement Learning

A Python-based reinforcement learning system for optimizing urban park design. This project uses Q-Learning to intelligently place park elements (benches, trees, fountains, lamps, etc.) to maximize comfort, utility, and aesthetic metrics.

##Features

- **Reinforcement Learning**: Q-Learning algorithm with experience replay
- **3D Visualization**: Real-time park rendering using Pygame and OpenGL
- **Multiple Park Elements**: Trees, benches, fountains, street lamps, grass patches, pathways
- **Smart Metrics**: Comfort scores, shade coverage, space utilization, distribution analysis
- **Agent Simulation**: Simulated pedestrians to evaluate park usability
- **Modular Architecture**: Clean separation of concerns with organized module structure

##Project Structure

```
urban-park-rl/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Main entry point
â”‚   â”œâ”€â”€ config.py               # Configuration and constants
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ park.py            # Park environment class
â”‚   â”‚   â”œâ”€â”€ elements.py        # Park elements (Tree, Bench, etc.)
â”‚   â”‚   â””â”€â”€ grid.py            # Grid system for placement
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pedestrian.py      # Pedestrian agent simulation
â”‚   â”‚   â””â”€â”€ movement.py        # Movement patterns and pathfinding
â”‚   â”‚
â”‚   â”œâ”€â”€ rl/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ q_learning.py      # Q-Learning implementation
â”‚   â”‚   â”œâ”€â”€ state.py           # State representation
â”‚   â”‚   â”œâ”€â”€ actions.py         # Action space definition
â”‚   â”‚   â””â”€â”€ replay_buffer.py   # Experience replay buffer
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ comfort.py         # Comfort score calculation
â”‚   â”‚   â”œâ”€â”€ utilization.py     # Space utilization metrics
â”‚   â”‚   â”œâ”€â”€ coverage.py        # Shade and lighting coverage
â”‚   â”‚   â””â”€â”€ distribution.py    # Element distribution analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ renderer.py        # 3D rendering engine
â”‚   â”‚   â”œâ”€â”€ camera.py          # Camera controls
â”‚   â”‚   â”œâ”€â”€ lighting.py        # Lighting system
â”‚   â”‚   â””â”€â”€ ui.py              # User interface components
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py          # Logging utilities
â”‚       â”œâ”€â”€ data_manager.py    # Save/load functionality
â”‚       â””â”€â”€ helpers.py         # Helper functions
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_environment.py
â”‚   â”œâ”€â”€ test_rl.py
â”‚   â”œâ”€â”€ test_metrics.py
â”‚   â””â”€â”€ test_agents.py
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_random.py     # Random baseline experiments
â”‚   â”œâ”€â”€ training_runs.py       # Training experiments
â”‚   â””â”€â”€ analysis.ipynb        # Jupyter notebook for analysis
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/               # Saved Q-tables and models
â”‚   â”œâ”€â”€ logs/                 # Training logs
â”‚   â””â”€â”€ results/              # Experiment results
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ textures/             # Texture files for 3D elements
â”‚   â”œâ”€â”€ models/               # 3D model files (if any)
â”‚   â””â”€â”€ icons/                # UI icons
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md       # System architecture
â”‚   â”œâ”€â”€ api.md                # API documentation
â”‚   â””â”€â”€ algorithms.md         # Algorithm explanations
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package setup
â”œâ”€â”€ .gitignore               # Git ignore file
â””â”€â”€ LICENSE                   # License file
```

## Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/urban-park-rl.git
cd urban-park-rl
```

2. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

##Usage

### Quick Start

Run the main simulation:
```bash
python src/main.py
```

### Training the RL Agent

```bash
python src/main.py --mode train --episodes 1000
```

### Testing with Random Baseline

```bash
python experiments/baseline_random.py
```

### Interactive Mode

```bash
python src/main.py --mode interactive
```

##Algorithm Details

The system uses Q-Learning with the following specifications:

- **State Space**: 3x3 grid representation with element encoding
- **Action Space**: Place element at position (6 element types Ã— 9 positions)
- **Reward Function**: Weighted combination of comfort, utilization, coverage, and distribution metrics
- **Learning Rate**: 0.1 (configurable)
- **Discount Factor**: 0.95 (configurable)
- **Epsilon**: 0.3 with decay (configurable)

##Metrics

1. **Comfort Score**: Evaluates placement of benches near shade and amenities
2. **Utilization**: Percentage of effectively used space
3. **Shade Coverage**: Tree canopy coverage percentage
4. **Distribution**: Uniformity of element placement
5. **Total Score**: Weighted combination of all metrics

##Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

##License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

##Acknowledgments

- Inspired by urban planning optimization research
- Built with Python scientific computing stack
- Special thanks to the reinforcement learning community

## ðŸ“§ Contact

Your Name - [@yourtwitter](https://twitter.com/yourtwitter) - email@example.com

Project Link: [https://github.com/yourusername/urban-park-rl](https://github.com/yourusername/urban-park-rl)
